#!/usr/bin/env python3
"""
Advanced Field Extraction Pipeline
Integrates field detection model with OCR processing for automatic field extraction.
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, asdict
import numpy as np
from datetime import datetime
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from field_detection_model import FieldCategoryClassifier, FieldDetectionResult
    from ocr import extract_text
    from ocr.rag_field_suggestion import RAGFieldSuggestionEngine, DocumentFieldKnowledgeBase
    from train_document_classifier import DocumentClassifierTrainer
except ImportError as e:
    print(f"Warning: Some imports failed: {e}")

@dataclass
class ExtractedField:
    """Represents an extracted field with comprehensive information."""
    field_name: str
    field_category: str
    category_type: str
    value: str
    confidence: float
    extraction_method: str  # 'pattern', 'ml', 'rag', 'hybrid'
    context: str
    validation_status: str  # 'valid', 'invalid', 'uncertain'
    coordinates: Optional[Tuple[int, int, int, int]] = None  # x, y, width, height

@dataclass
class DocumentFieldAnalysis:
    """Complete field analysis for a document."""
    document_type: str
    document_confidence: float
    total_fields_detected: int
    extraction_timestamp: str
    extracted_fields: List[ExtractedField]
    processing_time: float
    metadata: Dict[str, Any]

class AdvancedFieldExtractionPipeline:
    """Advanced pipeline for extracting fields from OCR text."""
    
    def __init__(self):
        """Initialize the advanced field extraction pipeline."""
        self.field_classifier = FieldCategoryClassifier()
        self.document_classifier = None
        self.rag_engine = None
        
        # Initialize models
        self._initialize_components()
        
        # Field validation rules
        self.validation_rules = self._initialize_validation_rules()
        
        print("üîß Advanced Field Extraction Pipeline initialized")
    
    def _initialize_components(self):
        """Initialize all pipeline components."""
        try:\n            # Try to load pre-trained field detection models\n            if not self.field_classifier.load_trained_models():\n                print(\"üîÑ Training new field detection models...\")\n                self.field_classifier.train_field_detection_models()\n                self.field_classifier.save_trained_models()\n            \n            # Initialize document classifier\n            try:\n                self.document_classifier = DocumentClassifierTrainer()\n                self.document_classifier.load_trained_model()\n                print(\"‚úÖ Document classifier loaded\")\n            except:\n                print(\"‚ö†Ô∏è Document classifier not available\")\n            \n            # Initialize RAG engine\n            try:\n                self.rag_engine = RAGFieldSuggestionEngine()\n                print(\"‚úÖ RAG engine initialized\")\n            except:\n                print(\"‚ö†Ô∏è RAG engine not available\")\n                \n        except Exception as e:\n            print(f\"‚ö†Ô∏è Warning during initialization: {e}\")\n    \n    def _initialize_validation_rules(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Initialize field validation rules.\"\"\"\n        return {\n            'aadhar_number': {\n                'pattern': r'^\\d{4}\\s*\\d{4}\\s*\\d{4}$',\n                'length': [12, 14],  # With/without spaces\n                'checksum': False  # Could implement Aadhar checksum validation\n            },\n            'pan_number': {\n                'pattern': r'^[A-Z]{5}\\d{4}[A-Z]$',\n                'length': [10],\n                'checksum': False\n            },\n            'mobile_number': {\n                'pattern': r'^(\\+91[\\s-]?)?[6-9]\\d{9}$',\n                'length': [10, 13, 14],\n                'checksum': False\n            },\n            'pin_code': {\n                'pattern': r'^\\d{6}$',\n                'length': [6],\n                'checksum': False\n            },\n            'voter_id': {\n                'pattern': r'^[A-Z]{3}\\d{7}$',\n                'length': [10],\n                'checksum': False\n            },\n            'email': {\n                'pattern': r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$',\n                'length': [5, 254],\n                'checksum': False\n            }\n        }\n    \n    def extract_fields_from_text(self, text: str, document_image_path: str = None) -> DocumentFieldAnalysis:\n        \"\"\"Extract fields from OCR text using multiple methods.\"\"\"\n        start_time = datetime.now()\n        \n        print(f\"\\nüîç Extracting fields from text...\")\n        print(f\"üìÑ Text length: {len(text)} characters\")\n        \n        # Step 1: Classify document type\n        document_type, doc_confidence = self._classify_document_type(text)\n        print(f\"üìã Document type: {document_type} (confidence: {doc_confidence:.3f})\")\n        \n        # Step 2: Extract fields using multiple methods\n        all_extracted_fields = []\n        \n        # Method 1: ML-based field detection\n        ml_fields = self._extract_fields_ml(text)\n        all_extracted_fields.extend(ml_fields)\n        \n        # Method 2: RAG-based field suggestion (if available)\n        if self.rag_engine:\n            rag_fields = self._extract_fields_rag(text, document_type)\n            all_extracted_fields.extend(rag_fields)\n        \n        # Method 3: Pattern-based extraction\n        pattern_fields = self._extract_fields_patterns(text)\n        all_extracted_fields.extend(pattern_fields)\n        \n        # Step 3: Merge and deduplicate fields\n        merged_fields = self._merge_and_deduplicate_fields(all_extracted_fields)\n        \n        # Step 4: Validate extracted fields\n        validated_fields = self._validate_extracted_fields(merged_fields)\n        \n        # Step 5: Create analysis result\n        processing_time = (datetime.now() - start_time).total_seconds()\n        \n        analysis = DocumentFieldAnalysis(\n            document_type=document_type,\n            document_confidence=doc_confidence,\n            total_fields_detected=len(validated_fields),\n            extraction_timestamp=datetime.now().isoformat(),\n            extracted_fields=validated_fields,\n            processing_time=processing_time,\n            metadata={\n                'text_length': len(text),\n                'image_path': document_image_path,\n                'extraction_methods': ['ml', 'rag', 'pattern'] if self.rag_engine else ['ml', 'pattern'],\n                'validation_applied': True\n            }\n        )\n        \n        print(f\"‚úÖ Extraction complete: {len(validated_fields)} fields in {processing_time:.2f}s\")\n        return analysis\n    \n    def _classify_document_type(self, text: str) -> Tuple[str, float]:\n        \"\"\"Classify the document type using available classifiers.\"\"\"\n        if self.document_classifier:\n            try:\n                result = self.document_classifier.predict_document_type(text)\n                return result['predicted_type'], result['confidence']\n            except:\n                pass\n        \n        # Fallback: simple keyword-based classification\n        text_lower = text.lower()\n        \n        if 'aadhar' in text_lower or 'aadhaar' in text_lower or 'uid' in text_lower:\n            return 'AADHAR_CARD', 0.8\n        elif 'pan' in text_lower and ('income tax' in text_lower or 'permanent account' in text_lower):\n            return 'PAN_CARD', 0.8\n        elif 'voter' in text_lower or 'epic' in text_lower or 'election' in text_lower:\n            return 'VOTER_ID', 0.8\n        elif 'bank' in text_lower and ('account' in text_lower or 'passbook' in text_lower):\n            return 'BANK_DOCUMENT', 0.7\n        else:\n            return 'UNKNOWN', 0.5\n    \n    def _extract_fields_ml(self, text: str) -> List[ExtractedField]:\n        \"\"\"Extract fields using ML-based field detection.\"\"\"\n        fields = []\n        \n        try:\n            detection_results = self.field_classifier.detect_fields_in_text(text)\n            \n            for result in detection_results:\n                field = ExtractedField(\n                    field_name=result.field_name,\n                    field_category=result.field_category,\n                    category_type=result.category_type,\n                    value=result.detected_value or '',\n                    confidence=result.confidence,\n                    extraction_method='ml',\n                    context=result.context,\n                    validation_status='pending'\n                )\n                fields.append(field)\n                \n        except Exception as e:\n            print(f\"‚ö†Ô∏è ML extraction failed: {e}\")\n        \n        return fields\n    \n    def _extract_fields_rag(self, text: str, document_type: str) -> List[ExtractedField]:\n        \"\"\"Extract fields using RAG-based suggestion.\"\"\"\n        fields = []\n        \n        try:\n            suggestions = self.rag_engine.suggest_fields(text, document_type)\n            \n            for suggestion in suggestions:\n                field = ExtractedField(\n                    field_name=suggestion.field_name,\n                    field_category=suggestion.field_type,\n                    category_type='rag_detected',\n                    value=suggestion.suggested_value,\n                    confidence=suggestion.confidence,\n                    extraction_method='rag',\n                    context=suggestion.source_text,\n                    validation_status='pending'\n                )\n                fields.append(field)\n                \n        except Exception as e:\n            print(f\"‚ö†Ô∏è RAG extraction failed: {e}\")\n        \n        return fields\n    \n    def _extract_fields_patterns(self, text: str) -> List[ExtractedField]:\n        \"\"\"Extract fields using pattern-based methods.\"\"\"\n        fields = []\n        \n        # Define comprehensive patterns\n        patterns = {\n            'aadhar_number': [\n                r'(?:Aadhar|AADHAR|Aadhaar|UID)\\s*:?\\s*(\\d{4}\\s*\\d{4}\\s*\\d{4})',\n                r'(\\d{4}\\s*\\d{4}\\s*\\d{4})'\n            ],\n            'pan_number': [\n                r'(?:PAN|Pan)\\s*:?\\s*([A-Z]{5}\\d{4}[A-Z])',\n                r'([A-Z]{5}\\d{4}[A-Z])'\n            ],\n            'mobile_number': [\n                r'(?:Mobile|Phone|Contact)\\s*:?\\s*(\\+91[\\s-]?\\d{10})',\n                r'(?:Mobile|Phone|Contact)\\s*:?\\s*(\\d{10})',\n                r'(\\+91[\\s-]?\\d{10})',\n                r'(\\b[6-9]\\d{9}\\b)'\n            ],\n            'email': [\n                r'(?:Email|E-mail)\\s*:?\\s*([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})',\n                r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n            ],\n            'full_name': [\n                r'(?:Name|NAME|Full Name)\\s*:?\\s*([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)',\n                r'(?:MR\\.|MS\\.|MRS\\.)\\s*([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)'\n            ],\n            'pin_code': [\n                r'(?:PIN|Pin|Pincode)\\s*:?\\s*(\\d{6})',\n                r'\\b(\\d{6})\\b'\n            ],\n            'voter_id': [\n                r'(?:EPIC|Epic|Voter)\\s*:?\\s*([A-Z]{3}\\d{7})',\n                r'([A-Z]{3}\\d{7})'\n            ]\n        }\n        \n        import re\n        \n        for field_name, field_patterns in patterns.items():\n            for pattern in field_patterns:\n                try:\n                    matches = re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE)\n                    \n                    for match in matches:\n                        value = match.group(1) if match.groups() else match.group(0)\n                        \n                        # Determine category type\n                        if field_name in ['aadhar_number', 'pan_number', 'voter_id']:\n                            category_type = 'identification'\n                        elif field_name in ['mobile_number', 'email']:\n                            category_type = 'contact'\n                        elif field_name in ['full_name']:\n                            category_type = 'personal'\n                        elif field_name in ['pin_code']:\n                            category_type = 'address'\n                        else:\n                            category_type = 'general'\n                        \n                        # Get context (surrounding text)\n                        start = max(0, match.start() - 30)\n                        end = min(len(text), match.end() + 30)\n                        context = text[start:end].replace('\\n', ' ').strip()\n                        \n                        field = ExtractedField(\n                            field_name=field_name,\n                            field_category=field_name,\n                            category_type=category_type,\n                            value=value.strip(),\n                            confidence=0.8,  # Default pattern confidence\n                            extraction_method='pattern',\n                            context=context,\n                            validation_status='pending'\n                        )\n                        fields.append(field)\n                        \n                except Exception as e:\n                    print(f\"‚ö†Ô∏è Pattern matching failed for {field_name}: {e}\")\n                    continue\n        \n        return fields\n    \n    def _merge_and_deduplicate_fields(self, fields: List[ExtractedField]) -> List[ExtractedField]:\n        \"\"\"Merge fields from different methods and remove duplicates.\"\"\"\n        # Group fields by field name\n        field_groups = {}\n        for field in fields:\n            key = field.field_name\n            if key not in field_groups:\n                field_groups[key] = []\n            field_groups[key].append(field)\n        \n        merged_fields = []\n        \n        for field_name, field_list in field_groups.items():\n            if len(field_list) == 1:\n                merged_fields.append(field_list[0])\n            else:\n                # Multiple detections for same field - choose best one\n                best_field = max(field_list, key=lambda f: f.confidence)\n                \n                # Combine extraction methods\n                methods = list(set(f.extraction_method for f in field_list))\n                best_field.extraction_method = '+'.join(sorted(methods))\n                \n                # Average confidence if multiple high-confidence detections\n                high_conf_fields = [f for f in field_list if f.confidence > 0.6]\n                if len(high_conf_fields) > 1:\n                    best_field.confidence = np.mean([f.confidence for f in high_conf_fields])\n                \n                merged_fields.append(best_field)\n        \n        # Sort by confidence\n        merged_fields.sort(key=lambda f: f.confidence, reverse=True)\n        \n        return merged_fields\n    \n    def _validate_extracted_fields(self, fields: List[ExtractedField]) -> List[ExtractedField]:\n        \"\"\"Validate extracted fields using predefined rules.\"\"\"\n        validated_fields = []\n        \n        for field in fields:\n            field.validation_status = self._validate_field_value(field.field_name, field.value)\n            validated_fields.append(field)\n        \n        return validated_fields\n    \n    def _validate_field_value(self, field_name: str, value: str) -> str:\n        \"\"\"Validate a field value against predefined rules.\"\"\"\n        if not value:\n            return 'invalid'\n        \n        # Get validation rules for this field\n        rules = self.validation_rules.get(field_name, {})\n        \n        if not rules:\n            return 'uncertain'  # No validation rules available\n        \n        import re\n        \n        # Check pattern\n        if 'pattern' in rules:\n            if not re.match(rules['pattern'], value):\n                return 'invalid'\n        \n        # Check length\n        if 'length' in rules:\n            clean_value = re.sub(r'\\s', '', value)  # Remove spaces for length check\n            if len(clean_value) not in rules['length']:\n                return 'invalid'\n        \n        # Additional validations can be added here\n        \n        return 'valid'\n    \n    def save_extraction_results(self, analysis: DocumentFieldAnalysis, output_path: str = None) -> str:\n        \"\"\"Save extraction results to JSON file.\"\"\"\n        if not output_path:\n            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n            output_path = f\"field_extraction_results_{timestamp}.json\"\n        \n        # Convert dataclass to dictionary\n        data = asdict(analysis)\n        \n        with open(output_path, 'w') as f:\n            json.dump(data, f, indent=2, default=str)\n        \n        print(f\"üíæ Results saved to: {output_path}\")\n        return output_path\n    \n    def create_extraction_summary(self, analysis: DocumentFieldAnalysis) -> str:\n        \"\"\"Create human-readable summary of extraction results.\"\"\"\n        summary = []\n        summary.append(f\"üìÑ FIELD EXTRACTION SUMMARY\")\n        summary.append(f\"=\" * 40)\n        summary.append(f\"Document Type: {analysis.document_type} (confidence: {analysis.document_confidence:.3f})\")\n        summary.append(f\"Fields Detected: {analysis.total_fields_detected}\")\n        summary.append(f\"Processing Time: {analysis.processing_time:.2f} seconds\")\n        summary.append(f\"Extraction Time: {analysis.extraction_timestamp}\")\n        summary.append(f\"\")\n        \n        if analysis.extracted_fields:\n            summary.append(f\"üîç EXTRACTED FIELDS:\")\n            summary.append(f\"-\" * 20)\n            \n            # Group by category type\n            categories = {}\n            for field in analysis.extracted_fields:\n                cat = field.category_type\n                if cat not in categories:\n                    categories[cat] = []\n                categories[cat].append(field)\n            \n            for category, fields in categories.items():\n                summary.append(f\"\\n{category.upper()} FIELDS:\")\n                for field in fields:\n                    status_icon = \"‚úÖ\" if field.validation_status == 'valid' else \"‚ö†Ô∏è\" if field.validation_status == 'uncertain' else \"‚ùå\"\n                    summary.append(f\"  {status_icon} {field.field_name}: '{field.value}' (conf: {field.confidence:.3f})\")\n                    summary.append(f\"    Method: {field.extraction_method} | Status: {field.validation_status}\")\n        else:\n            summary.append(f\"‚ùå No fields detected\")\n        \n        return \"\\n\".join(summary)\n\ndef test_field_extraction_pipeline():\n    \"\"\"Test the field extraction pipeline with sample documents.\"\"\"\n    print(\"üß™ Testing Advanced Field Extraction Pipeline\")\n    print(\"=\" * 50)\n    \n    # Initialize pipeline\n    pipeline = AdvancedFieldExtractionPipeline()\n    \n    # Sample OCR texts\n    test_documents = [\n        {\n            'name': 'Aadhar Card',\n            'text': \"\"\"GOVERNMENT OF INDIA\nUNIQUE IDENTIFICATION AUTHORITY OF INDIA\n\nName: RAJESH KUMAR\nS/O: RAM PRASAD\nDOB: 15/08/1990\nGender: MALE\n\nAadhar: 1234 5678 9012\nMobile: +91 9876543210\nAddress: 123 MG Road\nBangalore, Karnataka\nPIN: 560001\"\"\"\n        },\n        {\n            'name': 'PAN Card',\n            'text': \"\"\"INCOME TAX DEPARTMENT\nGOVERNMENT OF INDIA\nPermanent Account Number Card\n\nPAN: ABCDE1234F\nName: PRIYA SHARMA\nFather's Name: VIJAY SHARMA\nDate of Birth: 25/12/1985\nSignature\"\"\"\n        },\n        {\n            'name': 'Mixed Document',\n            'text': \"\"\"Contact Information:\nName: AMIT SINGH\nEmail: amit.singh@example.com\nMobile: 9123456789\nPAN: FGHIJ5678K\nVoter ID: DEF9876543\nPIN Code: 400001\"\"\"\n        }\n    ]\n    \n    results = []\n    \n    for i, doc in enumerate(test_documents, 1):\n        print(f\"\\nüìÑ Testing Document {i}: {doc['name']}\")\n        print(\"-\" * 40)\n        \n        # Extract fields\n        analysis = pipeline.extract_fields_from_text(doc['text'])\n        \n        # Create summary\n        summary = pipeline.create_extraction_summary(analysis)\n        print(summary)\n        \n        # Save results\n        output_file = f\"test_extraction_{i}.json\"\n        pipeline.save_extraction_results(analysis, output_file)\n        \n        results.append(analysis)\n    \n    print(f\"\\n‚úÖ Pipeline testing complete!\")\n    print(f\"üìä Total documents processed: {len(results)}\")\n    \n    return results\n\ndef main():\n    \"\"\"Main function for field extraction pipeline.\"\"\"\n    print(\"üéØ Advanced Field Extraction Pipeline\")\n    print(\"=\" * 45)\n    \n    try:\n        # Run tests\n        results = test_field_extraction_pipeline()\n        \n        # Summary statistics\n        total_fields = sum(len(analysis.extracted_fields) for analysis in results)\n        valid_fields = sum(sum(1 for field in analysis.extracted_fields if field.validation_status == 'valid') for analysis in results)\n        \n        print(f\"\\nüìà OVERALL STATISTICS\")\n        print(f\"-\" * 25)\n        print(f\"Total Fields Extracted: {total_fields}\")\n        print(f\"Valid Fields: {valid_fields}\")\n        print(f\"Validation Rate: {valid_fields/total_fields*100:.1f}%\" if total_fields > 0 else \"Validation Rate: N/A\")\n        \n        return True\n        \n    except Exception as e:\n        print(f\"‚ùå Pipeline test failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n\nif __name__ == \"__main__\":\n    success = main()\n    if not success:\n        sys.exit(1)